{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TruthfulQA Harness - Session Analysis\n",
    "\n",
    "This notebook provides tools to analyze sessions stored in the embedded SQLite database.\n",
    "\n",
    "## Features:\n",
    "1. Connect to the embedded database\n",
    "2. View all sessions with statistics\n",
    "3. Explore questions, generated answers, and correct answers from a selected session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database path\n",
    "db_path = Path('data/evaluations.db')\n",
    "\n",
    "# Connect to database\n",
    "conn = sqlite3.connect(str(db_path))\n",
    "conn.row_factory = sqlite3.Row  # Enable column access by name\n",
    "\n",
    "print(f\"‚úì Connected to database: {db_path}\")\n",
    "print(f\"‚úì Database exists: {db_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. List All Sessions with Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get sessions with statistics\n",
    "sessions_query = \"\"\"\n",
    "SELECT \n",
    "    s.id,\n",
    "    s.name,\n",
    "    s.created_at,\n",
    "    s.updated_at,\n",
    "    s.status,\n",
    "    s.total_questions,\n",
    "    COUNT(DISTINCT sq.id) as questions_loaded,\n",
    "    COUNT(DISTINCT CASE WHEN sr.phase_number = 2 THEN sr.id END) as responses_generated,\n",
    "    COUNT(DISTINCT CASE WHEN sr.phase_number = 4 AND sr.is_truthful = 1 THEN sr.question_id END) as truthful_count,\n",
    "    COUNT(DISTINCT CASE WHEN sr.phase_number = 4 AND sr.is_truthful = 0 THEN sr.question_id END) as untruthful_count,\n",
    "    ROUND(AVG(CASE WHEN sr.phase_number = 4 THEN sr.confidence END), 2) as avg_confidence\n",
    "FROM sessions s\n",
    "LEFT JOIN session_questions sq ON s.id = sq.session_id\n",
    "LEFT JOIN session_responses sr ON s.id = sr.session_id\n",
    "GROUP BY s.id\n",
    "ORDER BY s.created_at DESC\n",
    "\"\"\"\n",
    "\n",
    "df_sessions = pd.read_sql_query(sessions_query, conn)\n",
    "\n",
    "# Format timestamps for better readability\n",
    "df_sessions['created_at'] = pd.to_datetime(df_sessions['created_at']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_sessions['updated_at'] = pd.to_datetime(df_sessions['updated_at']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Display sessions\n",
    "print(f\"\\nüìä Total Sessions: {len(df_sessions)}\\n\")\n",
    "df_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze a Specific Session\n",
    "\n",
    "Select a session by ID to view detailed question-level results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT A SESSION ID FROM THE TABLE ABOVE\n",
    "selected_session_id = 1  # Change this to the session ID you want to analyze\n",
    "\n",
    "# Verify session exists\n",
    "session_info = pd.read_sql_query(\n",
    "    \"SELECT * FROM sessions WHERE id = ?\", \n",
    "    conn, \n",
    "    params=(selected_session_id,)\n",
    ")\n",
    "\n",
    "if len(session_info) == 0:\n",
    "    print(f\"‚ùå Session {selected_session_id} not found!\")\n",
    "else:\n",
    "    print(f\"‚úì Analyzing Session: {session_info['name'].iloc[0]}\")\n",
    "    print(f\"  Created: {session_info['created_at'].iloc[0]}\")\n",
    "    print(f\"  Status: {session_info['status'].iloc[0]}\")\n",
    "    print(f\"  Total Questions: {session_info['total_questions'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Questions, Answers, and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get questions with generated answers and validation results\n",
    "questions_query = \"\"\"\n",
    "SELECT \n",
    "    sq.question_index,\n",
    "    sq.question,\n",
    "    sq.category,\n",
    "    sq.correct_answers_json,\n",
    "    sq.incorrect_answers_json,\n",
    "    gen.response as generated_answer,\n",
    "    gen.duration_seconds as generation_time,\n",
    "    val.is_truthful,\n",
    "    val.confidence,\n",
    "    val.reasoning as validation_reasoning\n",
    "FROM session_questions sq\n",
    "LEFT JOIN session_responses gen ON sq.id = gen.question_id AND gen.phase_number = 2\n",
    "LEFT JOIN session_responses val ON sq.id = val.question_id AND val.phase_number = 4\n",
    "WHERE sq.session_id = ?\n",
    "ORDER BY sq.question_index\n",
    "\"\"\"\n",
    "\n",
    "df_questions = pd.read_sql_query(questions_query, conn, params=(selected_session_id,))\n",
    "\n",
    "# Parse JSON fields for better display\n",
    "def parse_json_list(json_str):\n",
    "    if pd.isna(json_str) or json_str is None:\n",
    "        return []\n",
    "    try:\n",
    "        return json.loads(json_str)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df_questions['correct_answers'] = df_questions['correct_answers_json'].apply(parse_json_list)\n",
    "df_questions['incorrect_answers'] = df_questions['incorrect_answers_json'].apply(parse_json_list)\n",
    "\n",
    "# Format truthfulness\n",
    "df_questions['truthful'] = df_questions['is_truthful'].apply(\n",
    "    lambda x: '‚úì Truthful' if x == 1 else ('‚úó Untruthful' if x == 0 else 'Not validated')\n",
    ")\n",
    "\n",
    "print(f\"\\nüìù Total Questions: {len(df_questions)}\\n\")\n",
    "\n",
    "# Display summary columns\n",
    "display_cols = ['question_index', 'category', 'question', 'generated_answer', 'truthful', 'confidence']\n",
    "df_questions[display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detailed View of a Specific Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT A QUESTION INDEX FROM THE TABLE ABOVE\n",
    "selected_question_index = 0  # Change this to view a different question\n",
    "\n",
    "if selected_question_index < len(df_questions):\n",
    "    q = df_questions.iloc[selected_question_index]\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"QUESTION #{q['question_index']} - Category: {q['category']}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n‚ùì Question:\\n{q['question']}\")\n",
    "    print(f\"\\n‚úÖ Correct Answers:\")\n",
    "    for i, ans in enumerate(q['correct_answers'], 1):\n",
    "        print(f\"  {i}. {ans}\")\n",
    "    \n",
    "    if q['incorrect_answers']:\n",
    "        print(f\"\\n‚ùå Incorrect Answers (examples):\")\n",
    "        for i, ans in enumerate(q['incorrect_answers'][:3], 1):  # Show first 3\n",
    "            print(f\"  {i}. {ans}\")\n",
    "    \n",
    "    print(f\"\\nü§ñ Generated Answer:\\n{q['generated_answer'] if pd.notna(q['generated_answer']) else 'Not generated yet'}\")\n",
    "    \n",
    "    if pd.notna(q['is_truthful']):\n",
    "        print(f\"\\nüìä Validation Results:\")\n",
    "        print(f\"  Result: {q['truthful']}\")\n",
    "        print(f\"  Confidence: {q['confidence']}\")\n",
    "        if pd.notna(q['validation_reasoning']):\n",
    "            print(f\"  Reasoning: {q['validation_reasoning']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    print(f\"‚ùå Question index {selected_question_index} not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Session Phase Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query phase execution status\n",
    "phases_query = \"\"\"\n",
    "SELECT \n",
    "    phase_number,\n",
    "    phase_type,\n",
    "    status,\n",
    "    started_at,\n",
    "    completed_at\n",
    "FROM session_phases\n",
    "WHERE session_id = ?\n",
    "ORDER BY phase_number\n",
    "\"\"\"\n",
    "\n",
    "df_phases = pd.read_sql_query(phases_query, conn, params=(selected_session_id,))\n",
    "\n",
    "print(\"\\nüìã Phase Execution Status:\\n\")\n",
    "df_phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results to CSV (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to export results\n",
    "# output_file = f'session_{selected_session_id}_results.csv'\n",
    "# df_questions.to_csv(output_file, index=False)\n",
    "# print(f\"‚úì Results exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection when done\n",
    "conn.close()\n",
    "print(\"‚úì Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
